{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "# Useful starting lines\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from used_functions import *\n",
    "from functions import *\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load data\n",
    "==="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from proj1_helpers import *\n",
    "\n",
    "labels, raw_data, indices = load_csv_data('train.csv', sub_sample=False)\n",
    "nan_data = meaningless_to_nan(raw_data)\n",
    "\n",
    "labels_te, raw_data_te, indices_te = load_csv_data('test.csv', sub_sample=False)\n",
    "nan_data_te = meaningless_to_nan(raw_data_te)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0  4  5  6 12 23 24 25 26 27 28]\n",
      "[ 0  4  5  6 12 23 24 25 26 27 28]\n"
     ]
    }
   ],
   "source": [
    "#Train\n",
    "n_samples, n_features = np.shape(nan_data)\n",
    "nan_columns = nan_find_columns(n_features, n_samples, nan_data)\n",
    "\n",
    "#Test\n",
    "n_samples_te, n_features_te = np.shape(raw_data_te)\n",
    "nan_columns_te = nan_find_columns(n_features_te, n_samples_te, nan_data_te)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Estimate whole features\n",
    "==="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1e-05\n",
      "0.0001\n",
      "0.0001\n",
      "0.0001\n",
      "0.0001\n",
      "1e-05\n",
      "0.001\n",
      "0.01\n",
      "0.001\n",
      "0.01\n",
      "0.01\n"
     ]
    }
   ],
   "source": [
    "# Estimation of columns for train set\n",
    "new_submatrix = np.delete(nan_data, nan_columns, axis = 1)\n",
    "k_fold = 4\n",
    "seed = 2\n",
    "lambdas = np.logspace(-5,-1,5)\n",
    "loss_te = np.ones(len(lambdas))\n",
    "loss_tr = np.ones(len(lambdas))\n",
    "\n",
    "for chosen_feature in nan_columns:\n",
    "    samples = []\n",
    "    for sample in range(n_samples):\n",
    "        if np.isnan(nan_data[sample,chosen_feature]):\n",
    "            samples.append(sample)\n",
    "    nan_lines = samples\n",
    "    new_submatrix0 = np.delete(new_submatrix,nan_lines, axis = 0)\n",
    "    labels_0 = np.delete(nan_data[:,chosen_feature],nan_lines, axis = 0)\n",
    "    k_indices = build_k_indices(labels_0, k_fold, seed)\n",
    "    for idx, lambda_ in enumerate(lambdas):\n",
    "        loss_tr[idx],loss_te[idx] = cross_validation(labels_0, new_submatrix0, k_indices, k_fold, lambda_, degree=1)\n",
    "    best_lambda = lambdas[np.argmin(loss_te)]\n",
    "    print((best_lambda))\n",
    "    weights, loss = ridge_regression(labels_0, new_submatrix0, best_lambda)\n",
    "    x_pred = np.dot(new_submatrix[nan_lines,:], weights)\n",
    "    nan_data[nan_lines,chosen_feature] = x_pred\n",
    "    #print(x_pred.shape)\n",
    "    \n",
    "estimated_data = nan_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.01\n",
      "1e-05\n",
      "1e-05\n",
      "1e-05\n",
      "1e-05\n",
      "1e-05\n",
      "1e-05\n",
      "1e-05\n",
      "1e-05\n",
      "1e-05\n",
      "1e-05\n"
     ]
    }
   ],
   "source": [
    "# Estimation of columns for test set\n",
    "new_submatrix_te = np.delete(nan_data_te,nan_columns, axis = 1)\n",
    "loss_te_ = np.ones(len(lambdas))\n",
    "loss_tr_ = np.ones(len(lambdas))\n",
    "for chosen_feature in nan_columns:\n",
    "    samples_te = []\n",
    "    for sample in range(n_samples_te):\n",
    "        if np.isnan(nan_data_te[sample,chosen_feature]):\n",
    "            samples_te.append(sample)\n",
    "    nan_lines_te = samples_te\n",
    "    new_submatrix0_te = np.delete(new_submatrix_te,nan_lines_te, axis = 0)\n",
    "    labels_0_te = np.delete(nan_data_te[:,chosen_feature],nan_lines_te, axis = 0)\n",
    "    k_indices_te = build_k_indices(labels_0_te, k_fold, seed)\n",
    "    for idx, lambda_ in enumerate(lambdas):\n",
    "        loss_tr_[idx],loss_te_[idx] = cross_validation(labels_0_te, new_submatrix0_te, k_indices_te, k_fold, lambda_, degree=1)\n",
    "    best_lambda_te = lambdas[np.argmin(loss_te)]\n",
    "    print((best_lambda_te))\n",
    "    weights_te, loss_te = ridge_regression(labels_0, new_submatrix0, best_lambda)\n",
    "    x_pred_te = np.dot(new_submatrix_te[nan_lines_te,:], weights_te)\n",
    "    nan_data_te[nan_lines_te,chosen_feature] = x_pred_te\n",
    "    #print(x_pred.shape)\n",
    "estimated_data_te = nan_data_te"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Find best parameters\n",
    "==="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-37-055a52c259ed>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mdegree_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdegree\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdegrees\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mlambda_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlambda_\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlambdas\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m         \u001b[0m_\u001b[0m \u001b[0;34m,\u001b[0m\u001b[0mloss_te\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdegree_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlambda_idx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscores\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdegree_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlambda_idx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclass_scores\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdegree_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlambda_idx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcross_validation_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mestimated_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mk_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mk_fold\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlambda_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdegree\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Degree:'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdegrees\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdegree_idx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Lambda:'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlambdas\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlambda_idx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Score:'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscores\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdegree_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlambda_idx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/GitHub/MachineLearning/project1/Scripts/used_functions.py\u001b[0m in \u001b[0;36mcross_validation_\u001b[0;34m(y, x, k_indices, k_fold, lambda_, degree)\u001b[0m\n\u001b[1;32m    409\u001b[0m         \u001b[0mx_tr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcatenate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlist_tr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    410\u001b[0m         \u001b[0;31m#form data with polynomial degree\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 411\u001b[0;31m         \u001b[0mpoly_tr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbuild_poly\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_tr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdegree\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    412\u001b[0m         \u001b[0mpoly_te\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbuild_poly\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_te\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdegree\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    413\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/GitHub/MachineLearning/project1/Scripts/utilitaries.py\u001b[0m in \u001b[0;36mbuild_poly\u001b[0;34m(x, degree)\u001b[0m\n\u001b[1;32m    122\u001b[0m     \u001b[0mpoly\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mones\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    123\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mdeg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdegree\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 124\u001b[0;31m         \u001b[0mpoly\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mc_\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpoly\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpower\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdeg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    125\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mpoly\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    126\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/numpy/lib/index_tricks.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    338\u001b[0m                 \u001b[0mobjs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mobjs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfinal_dtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    339\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 340\u001b[0;31m         \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcatenate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobjs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    341\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    342\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mmatrix\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#Parameters\n",
    "degrees = [9,10,11]\n",
    "lambdas = np.logspace(-9, -5, 10)\n",
    "k_fold = 4\n",
    "seed = 27\n",
    "\n",
    "k_idx = build_k_indices(labels, k_fold, seed)\n",
    "#loss_tr = np.ones((len(degrees),len(lambdas)))\n",
    "loss_te = np.ones((len(degrees),len(lambdas)))\n",
    "scores = np.ones((len(degrees),len(lambdas)))\n",
    "class_scores = np.ones((len(degrees),len(lambdas)))\n",
    "#labels = np.expand_dims(labels, axis=1) \n",
    "\n",
    "for degree_idx, degree in enumerate(degrees):\n",
    "    for lambda_idx, lambda_ in enumerate(lambdas):\n",
    "        _ ,loss_te[degree_idx, lambda_idx], scores[degree_idx, lambda_idx], class_scores[degree_idx, lambda_idx] = cross_validation_(labels, estimated_data, k_idx, k_fold, lambda_, degree)\n",
    "        print('Degree:', degrees[degree_idx], 'Lambda:', lambdas[lambda_idx])\n",
    "        print('Score:', scores[degree_idx, lambda_idx])\n",
    "        print('Class score:', class_scores[degree_idx, lambda_idx])\n",
    "        \n",
    "#Error        \n",
    "best_HP_idx = np.unravel_index(np.argmax(scores), np.shape(scores))\n",
    "best_degree = degrees[best_HP_idx[0]]\n",
    "best_lambda = lambdas[best_HP_idx[1]]\n",
    "best_score = scores[best_HP_idx[0], best_HP_idx[1]]\n",
    "#Class error\n",
    "best_HP_idx_class = np.unravel_index(np.argmax(class_scores), np.shape(class_scores))\n",
    "best_degree_class = degrees[best_HP_idx_class[0]]\n",
    "best_lambda_class = lambdas[best_HP_idx_class[1]]\n",
    "best_class_score = class_scores[best_HP_idx_class[0], best_HP_idx_class[1]]\n",
    "\n",
    "\n",
    "print('Best degree:', best_degree, 'Best lambda:', best_lambda, 'Best score:', best_score, 'Best class score:', best_class_score)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prediction\n",
    "==="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(568238,) (568238,)\n"
     ]
    }
   ],
   "source": [
    "# Train model to get weights\n",
    "poly_estimated_data = build_poly(estimated_data, best_degree_class)\n",
    "weights, loss = ridge_regression(labels, poly_estimated_data, best_lambda_class)\n",
    "\n",
    "#Predict on test\n",
    "poly_estimated_data_te = build_poly(estimated_data_te, best_degree_class)\n",
    "y_pred_te = predict_labels(weights, poly_estimated_data_te)\n",
    "\n",
    "print(np.shape(y_pred_te), np.shape(indices_te))\n",
    "create_csv_submission(indices_te, y_pred_te, 'submission_features_augmentation_ridgereg_2.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

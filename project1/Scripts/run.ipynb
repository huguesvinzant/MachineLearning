{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Useful starting lines\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from proj1_helpers import *\n",
    "from implementations import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Data loading\n",
    "labels, raw_data, indices = load_csv_data('train.csv', sub_sample=False)\n",
    "labels_te, raw_data_te, indices_te = load_csv_data('test.csv', sub_sample=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: 0 jet (99913, 30) , 1 jet (77544, 30) , 2 or more jets (72543, 30)\n",
      "Test: 0 jet (227458, 30) , 1 jet (175338, 30) , 2 or more jets (165442, 30)\n",
      "Columns with variance = 0 : (array([ 4,  5,  6, 12, 22, 23, 24, 25, 26, 27, 28, 29]),)\n",
      "New data shape : (99913, 18)\n",
      "Columns with variance = 0 : (array([ 4,  5,  6, 12, 22, 26, 27, 28]),)\n",
      "New data shape : (77544, 22)\n",
      "Columns with variance = 0 : (array([], dtype=int64),)\n",
      "New data shape : (72543, 30)\n",
      "26123 NaN lines found\n",
      "7562 NaN lines found\n",
      "4429 NaN lines found\n",
      "0 jet: Highly correlated indices [5, 2]\n",
      "1 jet: Highly correlated indices [21, 18, 2]\n",
      "2 or more jets: Highly correlated indices [29, 21, 2]\n"
     ]
    }
   ],
   "source": [
    "        # ----  DATA PREPROCESSING  ----\n",
    "\n",
    "#Data division according to jets\n",
    "\n",
    "print('Data processing...: Data division according to jets')\n",
    "labels0, data0, labels1, data1, labels2, data2 = divide_data(labels, raw_data)\n",
    "labels0_te, data0_te, labels1_te, data1_te, labels2_te, data2_te = divide_data(labels_te, raw_data_te)\n",
    "\n",
    "print('Data processing...: Train:', '0 jet', data0.shape, ', 1 jet', data1.shape, ', 2 or more jets', data2.shape)\n",
    "print('Data processing...: Test:', '0 jet', data0_te.shape, ', 1 jet', data1_te.shape, ', 2 or more jets', data2_te.shape)\n",
    "\n",
    "#Remove features with variance 0\n",
    "\n",
    "print('Data processing...: Remove features with null variance')\n",
    "clean_data0, clean_data0_te,no_var_columns0 = remove_novar_features(data0, data0_te)\n",
    "print('Data processing...: Columns of \"0 jet\" with variance = 0 :', no_var_columns0) \n",
    "print('Data processing...: New data shape \"0 jet\" :', clean_data0.shape) \n",
    "clean_data1, clean_data1_te,no_var_columns1 = remove_novar_features(data1, data1_te)\n",
    "print('Data processing...: Columns of \"1 jet\" with variance = 0 :', no_var_columns1)\n",
    "print('Data processing...: New data shape \"1 jet\" :', clean_data1.shape) \n",
    "clean_data2, clean_data2_te,no_var_columns2 = remove_novar_features(data2, data2_te)\n",
    "print('Data processing...: Columns of \"2 or more jets\" with variance = 0 :', no_var_columns2) \n",
    "print('Data processing...: New data shape  \"2 or more jets\" :', clean_data2.shape) \n",
    "\n",
    "model = input(\"Which model (A, B, C or D) do you want to use? \")\n",
    "\n",
    "\n",
    "#Data standardization\n",
    "\n",
    "\n",
    "print('Data processing...: Data standardization')\n",
    "std_data0, mean0, std0 = standardize_train(clean_data0, model) \n",
    "std_data0_te = standardize_test(clean_data0_te, mean0, std0, model)\n",
    "\n",
    "std_data1, mean1, std1 = standardize_train(clean_data1, model)\n",
    "std_data1_te = standardize_test(clean_data1_te, mean1, std1, model)\n",
    "\n",
    "std_data2, mean2, std2 = standardize_train(clean_data2, model)\n",
    "std_data2_te = standardize_test(clean_data2_te, mean2, std2, model)\n",
    "\n",
    "\n",
    "#Column 0 estimation or not\n",
    "\n",
    "if (model == A or model == C):\n",
    "    print('Data processing...: Estimation of column 0 using least squares')\n",
    "    estimated_data0, weights_train0 = column_estimation_train(std_data0)\n",
    "    estimated_data0_te = column_estimation_test(std_data0_te, weights_train0)\n",
    "\n",
    "    estimated_data1, weights_train1 = column_estimation_train(std_data1)\n",
    "    estimated_data1_te = column_estimation_test(std_data1_te, weights_train1)\n",
    "\n",
    "    estimated_data2, weights_train2 = column_estimation_train(std_data2)\n",
    "    estimated_data2_te = column_estimation_test(std_data2_te, weights_train2)\n",
    "\n",
    "if (model == B or model == D):\n",
    "    print('Data processing...: No column 0 estimation')\n",
    "    estimated_data0 = std_data0\n",
    "    estimated_data0_te = std_data0_te\n",
    "    \n",
    "    estimated_data1 = std_data1\n",
    "    estimated_data1_te = std_data1_te\n",
    "    \n",
    "    estimated_data1 = std_data0\n",
    "    estimated_data1_te = std_data1_te"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 jet: Best degree: 1 Best lambda: 0.1 Best score: 0.8138424582123911\n"
     ]
    }
   ],
   "source": [
    "        # ----  RIDGE REGRESSION  ----\n",
    "\n",
    "if (model == A or model == B):\n",
    "    #Define parameters\n",
    "    degrees = [9,10,11,12,13]\n",
    "    lambdas = np.logspace(-1, -5, 5)\n",
    "    k_fold = 10\n",
    "    seed = 23\n",
    "\n",
    "    #Find best parameters (cross validation)\n",
    "    print('Ridge regression... : Finding best parameters with cross validation...')\n",
    "    best_degree0, best_lambda0, best_score0, _ = find_best_parameters_general(labels0, estimated_data0, k_fold, seed, lambdas=lambdas, degrees=degrees)\n",
    "    print('Ridge regression... : 0 jet:', 'Best degree:', best_degree0, 'Best lambda:', best_lambda0, 'Best score:', best_score0)\n",
    "\n",
    "    best_degree1, best_lambda1,  best_score1, _ = find_best_parameters_general(labels1, estimated_data1, k_fold, seed, lambdas=lambdas, degrees=degrees)\n",
    "    print('Ridge regression... : 1 jet:', 'Best degree:', best_degree1, 'Best lambda:', best_lambda1, 'Best score:', best_score1)\n",
    "\n",
    "    best_degree2, best_lambda2, best_score2, _ = find_best_parameters_general(labels2, estimated_data2, k_fold, seed, lambdas=lambdas, degrees=degrees)\n",
    "    print('Ridge regression... : 2 or more jets:', 'Best degree:', best_degree2, 'Best lambda:', best_lambda2, 'Best score:', best_score2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots()\n",
    "im = ax.imshow((scores0.T*100), cmap='Blues')\n",
    "clb = ax.figure.colorbar(im, fraction=0.05, pad=0.02)\n",
    "clb.set_label('Accuracy', rotation=-90, va=\"bottom\")\n",
    "ax.set_xticks(np.arange(scores0.shape[0]))\n",
    "ax.set_yticks(np.arange(scores0.shape[1]))\n",
    "ax.set_xticklabels(degrees)\n",
    "ax.set_yticklabels(lambdas)\n",
    "ax.set_xlabel('Degree')\n",
    "ax.set_ylabel('Lambda')\n",
    "plt.title('0 jet')\n",
    "plt.show()\n",
    "plt.savefig('color_jet0.png')\n",
    "\n",
    "#plt.plot(degrees, np.mean(scores0, axis = 1), label = '0 jet')\n",
    "#plt.plot(degrees, np.mean(scores1, axis = 1), label = '1 jet')\n",
    "#plt.plot(degrees, np.mean(scores2, axis = 1), label = '2 or more jets')\n",
    "#plt.ylabel('Accuracy')\n",
    "#plt.xlabel('Degree')\n",
    "#plt.legend()\n",
    "#plt.show\n",
    "#plt.savefig('plot.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Prediction making\n",
    "y_pred0 = make_predictions(estimated_data0, labels0, estimated_data0_te, best_lambda0, best_degree0)\n",
    "y_pred1 = make_predictions(estimated_data1, labels1, estimated_data1_te, best_lambda1, best_degree1)\n",
    "y_pred2 = make_predictions(estimated_data2, labels2, estimated_data2_te, best_lambda2, best_degree0)\n",
    "\n",
    "#Submission making\n",
    "labels_te[np.where(raw_data_te[:,22] == 0)[0]] = y_pred0\n",
    "labels_te[np.where(raw_data_te[:,22] == 1)[0]] = y_pred1\n",
    "labels_te[np.where(raw_data_te[:,22] > 1)[0]] = y_pred2\n",
    "\n",
    "create_csv_submission(indices_te, labels_te, 'test_jet.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "jet0: Best degree: 3 Best lambda: 0.1 Best score: 0.7917826043439096\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-40-fe13511c12b6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'jet0:'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Best degree:'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbest_degree0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Best lambda:'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbest_lambda0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Best score:'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbest_score0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m \u001b[0mbest_degree1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbest_lambda1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbest_score1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfind_best_parameters_general\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mestimated_data1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mk_fold\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mseed\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlambdas\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlambdas\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgamma\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mgamma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdegrees\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdegrees\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'jet1:'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Best degree:'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbest_degree1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Best lambda:'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbest_lambda1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Best score:'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbest_score1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/GitHub/MachineLearning/project1/Scripts/implementations.py\u001b[0m in \u001b[0;36mfind_best_parameters_general\u001b[0;34m(labels, data, k_fold, seed, **param)\u001b[0m\n\u001b[1;32m    284\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mlambda_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlambda_\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparam\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'lambdas'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    285\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;34m'gamma'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mparam\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 286\u001b[0;31m                     \u001b[0mscores\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdegree_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlambda_idx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcross_validation_general\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mk_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mk_fold\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlambda_\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlambda_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdegree\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdegree\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgamma\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparam\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'gamma'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    287\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    288\u001b[0m                 \u001b[0mscores\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdegree_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlambda_idx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcross_validation_general\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mk_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mk_fold\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlambda_\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlambda_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdegree\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdegree\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/GitHub/MachineLearning/project1/Scripts/implementations.py\u001b[0m in \u001b[0;36mcross_validation_general\u001b[0;34m(y, x, k_indices, k_fold, **param)\u001b[0m\n\u001b[1;32m    260\u001b[0m             \u001b[0minitial_w\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpoly_tr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    261\u001b[0m             \u001b[0mmax_iters\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m100\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 262\u001b[0;31m             \u001b[0mw\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mreg_logistic_regression\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_tr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpoly_tr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparam\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'lambda_'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minitial_w\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_iters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparam\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'gamma'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    263\u001b[0m             \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpredict_labels_log\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpoly_te\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    264\u001b[0m             \u001b[0mscore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_pred\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0my_te\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_te\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/GitHub/MachineLearning/project1/Scripts/implementations.py\u001b[0m in \u001b[0;36mreg_logistic_regression\u001b[0;34m(y, x, lambda_, initial_w, max_iters, gamma)\u001b[0m\n\u001b[1;32m    101\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0miter\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmax_iters\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m         \u001b[0mprevious_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 103\u001b[0;31m         \u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweights\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlearning_by_penalized_gradient\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweights\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgamma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlambda_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    104\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0miter\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;36m30\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mabs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprevious_loss\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mupdate_tol\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/GitHub/MachineLearning/project1/Scripts/implementations.py\u001b[0m in \u001b[0;36mlearning_by_penalized_gradient\u001b[0;34m(y, tx, w, gamma, lambda_)\u001b[0m\n\u001b[1;32m    173\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    174\u001b[0m     \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcalculate_logistic_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m+\u001b[0m \u001b[0mlambda_\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 175\u001b[0;31m     \u001b[0mgrad\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcalculate_logistic_gradient\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mw\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m2\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mlambda_\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mw\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    176\u001b[0m     \u001b[0mnew_w\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mw\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mgamma\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mgrad\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    177\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/GitHub/MachineLearning/project1/Scripts/implementations.py\u001b[0m in \u001b[0;36mcalculate_logistic_gradient\u001b[0;34m(y, tx, w)\u001b[0m\n\u001b[1;32m    152\u001b[0m     \u001b[0;34m\"\"\"Compute the gradient of loss for sigmoidal prediction.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    153\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 154\u001b[0;31m     \u001b[0mpred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msigmoid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    155\u001b[0m     \u001b[0merr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpred\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    156\u001b[0m     \u001b[0mgrad\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m@\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/GitHub/MachineLearning/project1/Scripts/implementations.py\u001b[0m in \u001b[0;36msigmoid\u001b[0;34m(t)\u001b[0m\n\u001b[1;32m    136\u001b[0m     \u001b[0;34m\"\"\"Apply sigmoid function on t.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    137\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 138\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0;36m1.0\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    139\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    140\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "        # ----  LOGISTIC REGRESSION  ----\n",
    "\n",
    "if (model == C or model == D):\n",
    "    #Labels conversion to binary values\n",
    "\n",
    "    labels0[labels0 == -1] = 0\n",
    "    labels1[labels1 == -1] = 0\n",
    "    labels2[labels2 == -1] = 0\n",
    "\n",
    "    #Define parameters\n",
    "\n",
    "    degrees = range(5)\n",
    "    lambdas = np.logspace(-1, -5, 5)\n",
    "    k_fold = 10\n",
    "    gamma = 1e-5\n",
    "\n",
    "    #Find best parameters (cross validation)\n",
    "\n",
    "    print('Logistic regression...: Finding best parameters with cross validation...')\n",
    "    best_degree0, best_lambda0, best_score0, _ = find_best_parameters_general(labels0, estimated_data0, k_fold, seed, lambdas=lambdas, degrees=degrees, gamma=gamma)\n",
    "    print('Logistic regression...: 0 jet:', 'Best degree:', best_degree0, 'Best lambda:', best_lambda0, 'Best score:', best_score0)\n",
    "\n",
    "    best_degree1, best_lambda1, best_score1, _ = find_best_parameters_general(labels1, estimated_data1, k_fold, seed, lambdas=lambdas, gamma=gamma, degrees=degrees)\n",
    "    print('Logistic regression...: 1 jet:', 'Best degree:', best_degree1, 'Best lambda:', best_lambda1, 'Best score:', best_score1)\n",
    "\n",
    "    best_degree2, best_lambda2, best_score2, _ = find_best_parameters_general(labels2, estimated_data2, k_fold, seed, lambdas=lambdas, gamma=gamma, degrees=degrees)\n",
    "    print('Logistic regression...: 2 or more jets:', 'Best degree:', best_degree2, 'Best lambda:', best_lambda2, 'Best score:', best_score2)\n",
    "\n",
    "    #Prediction \n",
    "\n",
    "    max_iters = 1000\n",
    "    y_pred0 = make_predictions_log(estimated_data0, labels0, estimated_data0_te, best_lambda0, best_degree0, max_iters, gamma)\n",
    "    y_pred1 = make_predictions_log(estimated_data1, labels1, estimated_data1_te, best_lambda1, best_degree1, max_iters, gamma)\n",
    "    y_pred2 = make_predictions_log(estimated_data2, labels2, estimated_data2_te, best_lambda2, best_degree2, max_iters, gamma)\n",
    "\n",
    "    #Submission \n",
    "\n",
    "    labels_te[np.where(raw_data_te[:,22] == 0)[0]] = y_pred0\n",
    "    labels_te[np.where(raw_data_te[:,22] == 1)[0]] = y_pred1\n",
    "    labels_te[np.where(raw_data_te[:,22] > 1)[0]] = y_pred2\n",
    "\n",
    "    create_csv_submission(indices_te, labels_te, 'jet_log.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Prediction making\n",
    "y_pred0 = make_predictions_log(estimated_data0, labels0, estimated_data0_te, best_lambda0, best_degree0, max_iters, gamma)\n",
    "y_pred1 = make_predictions_log(estimated_data1, labels1, estimated_data1_te, best_lambda1, best_degree1, max_iters, gamma)\n",
    "y_pred2 = make_predictions_log(estimated_data2, labels2, estimated_data2_te, best_lambda2, best_degree2, max_iters, gamma)\n",
    "\n",
    "#Submission making\n",
    "labels_te[np.where(raw_data_te[:,22] == 0)[0]] = y_pred0\n",
    "labels_te[np.where(raw_data_te[:,22] == 1)[0]] = y_pred1\n",
    "labels_te[np.where(raw_data_te[:,22] > 1)[0]] = y_pred2\n",
    "\n",
    "create_csv_submission(indices_te, labels_te, 'jet_log.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Useful starting lines\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from proj1_helpers import *\n",
    "from essential_functions import *\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from proj1_helpers import *\n",
    "\n",
    "labels, raw_data, indices = load_csv_data('train.csv', sub_sample=False)\n",
    "nan_data = meaningless_to_nan(raw_data)\n",
    "\n",
    "labels_te, raw_data_te, indices_te = load_csv_data('test.csv', sub_sample=False)\n",
    "nan_data_te = meaningless_to_nan(raw_data_te)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columns containing NaN [ 0  4  5  6 12 23 24 25 26 27 28]\n"
     ]
    }
   ],
   "source": [
    "# Estimation of columns for train and test set\n",
    "estimated_data,nan_columns_train,weights_train = column_estimation_train(nan_data)\n",
    "estimated_data_te = column_estimation_test(nan_data_te,nan_columns_train,weights_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standardization of train and test set\n",
    "std_data, mean_train, std_train = standardize_train(estimated_data)\n",
    "std_data_te = standardize_test(estimated_data_te, mean_train, std_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current iteration=0, loss=142125.84279521107\n",
      "Current iteration=1, loss=152744.02554437096\n",
      "Current iteration=2, loss=211385.13826535456\n",
      "Current iteration=3, loss=163659.6956776539\n",
      "Current iteration=4, loss=146945.4459948694\n",
      "Current iteration=5, loss=163621.17030226608\n",
      "Current iteration=6, loss=174587.0528602529\n",
      "Current iteration=7, loss=189649.38263746275\n",
      "Current iteration=8, loss=165100.95943549796\n",
      "Current iteration=9, loss=145003.90798453978\n",
      "Current iteration=0, loss=142125.84279521107\n",
      "Current iteration=1, loss=152744.02580391883\n",
      "Current iteration=2, loss=211388.0835468628\n",
      "Current iteration=3, loss=163659.99850421515\n",
      "Current iteration=4, loss=146945.25302242764\n",
      "Current iteration=5, loss=163626.89009716117\n",
      "Current iteration=6, loss=174592.09151880394\n",
      "Current iteration=7, loss=189642.94077677932\n",
      "Current iteration=8, loss=165104.98573999773\n",
      "Current iteration=9, loss=145004.3927436958\n",
      "[142125.84279521107, 152744.02580391883, 211388.0835468628, 163659.99850421515, 146945.25302242764, 163626.89009716117, 174592.09151880394, 189642.94077677932, 165104.98573999773, 145004.3927436958]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "labels[labels == -1] = 0\n",
    "initial_w,_ = least_squares(labels, std_data)\n",
    "max_iters = 10\n",
    "gamma = 1e-02\n",
    "lambda_=1e-02\n",
    "\n",
    "losses,w_l = logistic_regression(labels,std_data, initial_w,max_iters, gamma)\n",
    "losses,w_r = reg_logistic_regression(labels,std_data, lambda_, initial_w,max_iters, gamma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current iteration=0, loss=142125.84279521107\n",
      "Current iteration=1, loss=142124.55491977293\n",
      "Current iteration=2, loss=142124.33560159692\n",
      "Current iteration=3, loss=142125.13274589102\n",
      "Current iteration=4, loss=142126.89648063277\n",
      "Current iteration=5, loss=142129.57906438666\n",
      "Current iteration=6, loss=142133.1347977006\n",
      "Current iteration=7, loss=142137.5199379737\n",
      "Current iteration=8, loss=142142.69261768967\n",
      "Current iteration=9, loss=142148.61276590818\n",
      "losses 142148.61276590818\n",
      "Current iteration=0, loss=142125.84279521107\n",
      "Current iteration=1, loss=142125.6648925387\n",
      "Current iteration=2, loss=142125.49811359818\n",
      "Current iteration=3, loss=142125.34240348358\n",
      "Current iteration=4, loss=142125.19770752674\n",
      "Current iteration=5, loss=142125.06397129653\n",
      "Current iteration=6, loss=142124.94114059786\n",
      "Current iteration=7, loss=142124.8291614707\n",
      "Current iteration=8, loss=142124.7279801888\n",
      "Current iteration=9, loss=142124.63754325896\n",
      "losses 142124.63754325896\n",
      "Current iteration=0, loss=142125.84279521107\n",
      "Current iteration=1, loss=142125.82450802927\n",
      "Current iteration=2, loss=142125.80633253214\n",
      "Current iteration=3, loss=142125.78826866453\n",
      "Current iteration=4, loss=142125.7703163713\n",
      "Current iteration=5, loss=142125.75247559734\n",
      "Current iteration=6, loss=142125.7347462874\n",
      "Current iteration=7, loss=142125.71712838646\n",
      "Current iteration=8, loss=142125.69962183942\n",
      "Current iteration=9, loss=142125.68222659134\n",
      "losses 142125.68222659134\n"
     ]
    }
   ],
   "source": [
    "lambdas = np.logspace(-8, -10, 3)\n",
    "losses = np.zeros(len(lambdas))\n",
    "for lambda_idx, lambda_ in enumerate(lambdas):\n",
    "    loss,w_l = logistic_regression(labels,std_data, initial_w,max_iters, lambda_)\n",
    "    losses[lambda_idx] = loss[-1]\n",
    "    print('losses',losses[lambda_idx])\n",
    "best_idx = np.argmin(losses)\n",
    "best_lambda = lambdas[best_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current iteration=0, loss=236189.7304869423\n",
      "Current iteration=1, loss=nan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/gaia/Documents/GitHub/MachineLearning/project1/Scripts/essential_functions.py:201: RuntimeWarning: divide by zero encountered in log\n",
      "  loss = y.T.dot(np.log(pred)) + (1.0 - y).T.dot(np.log(1.0 - pred))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current iteration=2, loss=nan\n",
      "Current iteration=3, loss=nan\n",
      "Current iteration=4, loss=nan\n",
      "Current iteration=5, loss=nan\n",
      "Current iteration=6, loss=nan\n",
      "Current iteration=7, loss=nan\n",
      "Current iteration=8, loss=nan\n",
      "Current iteration=9, loss=nan\n",
      "Current iteration=10, loss=nan\n",
      "Current iteration=11, loss=nan\n",
      "Current iteration=12, loss=nan\n",
      "Current iteration=13, loss=nan\n",
      "Current iteration=14, loss=nan\n",
      "Current iteration=15, loss=nan\n",
      "Current iteration=16, loss=nan\n",
      "Current iteration=17, loss=nan\n",
      "Current iteration=18, loss=nan\n",
      "Current iteration=19, loss=nan\n",
      "Current iteration=20, loss=nan\n",
      "Current iteration=21, loss=nan\n",
      "Current iteration=22, loss=nan\n",
      "Current iteration=23, loss=nan\n",
      "Current iteration=24, loss=nan\n",
      "Current iteration=25, loss=nan\n",
      "Current iteration=26, loss=nan\n",
      "Current iteration=27, loss=nan\n",
      "Current iteration=28, loss=nan\n",
      "Current iteration=29, loss=nan\n",
      "Current iteration=30, loss=nan\n",
      "Current iteration=31, loss=nan\n",
      "Current iteration=32, loss=nan\n",
      "Current iteration=33, loss=nan\n",
      "Current iteration=34, loss=nan\n",
      "Current iteration=35, loss=nan\n",
      "Current iteration=36, loss=nan\n",
      "Current iteration=37, loss=nan\n",
      "Current iteration=38, loss=nan\n",
      "Current iteration=39, loss=nan\n",
      "Current iteration=40, loss=nan\n",
      "Current iteration=41, loss=nan\n",
      "Current iteration=42, loss=nan\n",
      "Current iteration=43, loss=nan\n",
      "Current iteration=44, loss=nan\n",
      "Current iteration=45, loss=nan\n",
      "Current iteration=46, loss=nan\n",
      "Current iteration=47, loss=nan\n",
      "Current iteration=48, loss=nan\n",
      "Current iteration=49, loss=nan\n",
      "Current iteration=50, loss=nan\n",
      "Current iteration=51, loss=nan\n",
      "Current iteration=52, loss=nan\n",
      "Current iteration=53, loss=nan\n",
      "Current iteration=54, loss=nan\n",
      "Current iteration=55, loss=nan\n",
      "Current iteration=56, loss=nan\n",
      "Current iteration=57, loss=nan\n",
      "Current iteration=58, loss=nan\n",
      "Current iteration=59, loss=nan\n",
      "Current iteration=60, loss=nan\n",
      "Current iteration=61, loss=nan\n",
      "Current iteration=62, loss=nan\n",
      "Current iteration=63, loss=nan\n",
      "Current iteration=64, loss=nan\n",
      "Current iteration=65, loss=nan\n",
      "Current iteration=66, loss=nan\n",
      "Current iteration=67, loss=nan\n",
      "Current iteration=68, loss=nan\n",
      "Current iteration=69, loss=nan\n",
      "Current iteration=70, loss=nan\n",
      "Current iteration=71, loss=nan\n",
      "Current iteration=72, loss=nan\n",
      "Current iteration=73, loss=nan\n",
      "Current iteration=74, loss=nan\n",
      "Current iteration=75, loss=nan\n",
      "Current iteration=76, loss=nan\n",
      "Current iteration=77, loss=nan\n",
      "Current iteration=78, loss=nan\n",
      "Current iteration=79, loss=nan\n",
      "Current iteration=80, loss=nan\n",
      "Current iteration=81, loss=nan\n",
      "Current iteration=82, loss=nan\n",
      "Current iteration=83, loss=nan\n",
      "Current iteration=84, loss=nan\n",
      "Current iteration=85, loss=nan\n",
      "Current iteration=86, loss=nan\n",
      "Current iteration=87, loss=nan\n",
      "Current iteration=88, loss=nan\n",
      "Current iteration=89, loss=nan\n",
      "Current iteration=90, loss=nan\n",
      "Current iteration=91, loss=nan\n",
      "Current iteration=92, loss=nan\n",
      "Current iteration=93, loss=nan\n",
      "Current iteration=94, loss=nan\n",
      "Current iteration=95, loss=nan\n",
      "Current iteration=96, loss=nan\n",
      "Current iteration=97, loss=nan\n",
      "Current iteration=98, loss=nan\n",
      "Current iteration=99, loss=nan\n"
     ]
    }
   ],
   "source": [
    "# Train model to get weights\n",
    "best_degree = 11\n",
    "poly_std_data = build_poly(std_data, best_degree)\n",
    "initial_w,_ = least_squares(labels, poly_std_data)\n",
    "max_iters = 100\n",
    "lambda_ = 1e-09\n",
    "loss,weights = logistic_regression(labels,poly_std_data, initial_w,max_iters, lambda_)\n",
    "\n",
    "#Predict on test\n",
    "poly_std_data_te = build_poly(std_data_te, best_degree)\n",
    "y_pred_te = predict_labels(weights, poly_std_data_te)\n",
    "\n",
    "create_csv_submission(indices_te, y_pred_te, 'trywithlogisticreg.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
